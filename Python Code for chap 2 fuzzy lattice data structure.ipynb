{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python code for Chapter 2: Hospital Accessibility Catchment Areas as a Fuzzy Lattice Data Structure for toy example. Please note that the data used in the hospital catchment areas is not publically available and cannot be uploaded in this repository. Data ethics clearance number NAS003/2023.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the relevant packages. This code was run on python 3.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: The names in the structured nodes (1-9) are in the ordered format for V that the labelled states are first  i.e. grid_name={1,2,3,4,5,6,7,8,9}={v2,v7,v1,v3,v4,v5,v6,v8,v9}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grid_Name  Grid_Name2  Absorbant_State  Absorbant_State2 Label_val\n",
      "0          1           1                1                 1        P1\n",
      "1          3           1                0                 1        U3\n",
      "2          4           1                0                 1        U4\n",
      "3          6           1                0                 1        U6\n",
      "4          2           2                1                 1        P2\n"
     ]
    }
   ],
   "source": [
    "#Import Grid_Neighbours_Labels. \n",
    "# Grid_Name and Grid_Name2 indicates the the structural nodes adjacent to each other. \n",
    "# Absorbant_State indicates if grid_name is absorbant(1) or not and same for Absorbant_State2 for grid_name2. \n",
    "# Label_Val indicates the label associated with Grid_Name where for the toy example, P1 and P1 indicates the two POIs and U3-U9 indicates unlabelled.\n",
    "\n",
    "# Define the base path\n",
    "base_path = '//cenana01/testcode/pythonUserVenv/michelled/Virtual_Environment/PhD/Chapter 2/'\n",
    "file_path = os.path.join(base_path, 'Grid_Neighbours_Labels.txt')\n",
    "\n",
    "# Read the file\n",
    "DF = pd.read_csv(file_path, sep='|')\n",
    "print(DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_Name  Absorbant_State  Total\n",
      "0          1                1      3\n",
      "1          2                1      2\n",
      "2          3                0      2\n",
      "3          4                0      2\n",
      "4          5                0      3\n"
     ]
    }
   ],
   "source": [
    "# Degrees File. Distinct on grid_name and give the total number of neighbouring structural nodes(total) and if it is an absorbent state\n",
    "# Define the base path\n",
    "file_path2 = os.path.join(base_path, 'Grid_Degrees.txt')\n",
    "\n",
    "# Read the file\n",
    "DF2 = pd.read_csv(file_path2, sep='|')\n",
    "print(DF2.head())\n",
    "\n",
    "absorbant_States=sum(DF2.Absorbant_State)\n",
    "nodes=len(DF2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Using the information from DF create adjacency matrix \n",
    "df = pd.crosstab(DF.Grid_Name, DF.Grid_Name2)\n",
    "idx = df.columns.union(df.index)\n",
    "df = df.reindex(index = idx, columns=idx, fill_value=0)\n",
    "\n",
    "#Create correct format in Links table (new adjacency matrix)\n",
    "adjacency_matrix = np.matrix(df).astype(np.float64)\n",
    "identity_abs = np.identity(absorbant_States)\n",
    "#Absorbent states should only indicate 1 to own state, nullify absorbent states and replace top left hand corner of matrix with identity matrix\n",
    "adjacency_matrix[0:absorbant_States]=0\n",
    "#Replace the identity matrix in the top left hand corner of links matrix that all absorbent states can only move into themselves\n",
    "adjacency_matrix[0:absorbant_States,0:absorbant_States]=identity_abs\n",
    "\n",
    "#Links is now the adjacency matrix but all absorbent states only has a probability of 1 to stay in the same state with the rest 0\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 9 nodes and 14 edges\n"
     ]
    }
   ],
   "source": [
    "df2 = np.diag(DF2.Total)\n",
    "\n",
    "degree_matrix = np.matrix(df2)\n",
    "#Replace the identity matrix in the top left hand corner of degree matrix \n",
    "degree_matrix[0:absorbant_States,0:absorbant_States]=identity_abs\n",
    "\n",
    "# Verify dimension consistency\n",
    "num_nodes_degree, _ = degree_matrix.shape\n",
    "num_nodes_adjacency, _ = adjacency_matrix.shape\n",
    "\n",
    "if num_nodes_degree != num_nodes_adjacency:\n",
    "    print(\"Error: Degree and adjacency matrices have different dimensions.\")\n",
    "\n",
    "# Check the dimensions of the adjacency matrix\n",
    "num_rows, num_cols = adjacency_matrix.shape\n",
    "\n",
    "if num_rows != num_cols:\n",
    "    print(\"Error: Adjacency matrix must be square.\")\n",
    "    # Handle the error appropriately\n",
    "\n",
    "# Create a graph from the adjacency matrix\n",
    "GM = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "print(GM)\n",
    "\n",
    "absorbent_states = list(range(absorbant_States))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the degree information to the nodes\n",
    "for i, node in enumerate(GM.nodes()):\n",
    "    # Ensure that the index i is within bounds of the degree matrix\n",
    "    if i < len(degree_matrix):\n",
    "        # Use the node index directly to access the corresponding degree\n",
    "        GM.nodes[node]['degree'] = degree_matrix[i]\n",
    "    else:\n",
    "        print(f\"Index {i} is out of bounds for the degree matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label proagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation_with_absorbent_states(G, absorbent_states, max_iter=100):\n",
    "    \"\"\"\n",
    "    Label propagation algorithm implementation with absorbent states.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: NetworkX graph object.\n",
    "    - absorbent_states: List of absorbent states (nodes).\n",
    "    - max_iter: Maximum number of iterations.\n",
    "    \n",
    "    Returns:\n",
    "    - A matrix where each row corresponds to a node and each column corresponds to an absorbent state.\n",
    "    - Each element represents the probability of a node ending up in an absorbent state.\n",
    "    \"\"\"\n",
    "    # Initialize probabilities matrix with zeros\n",
    "    num_nodes = len(G)\n",
    "    num_absorbent_states = len(absorbent_states)\n",
    "    probabilities_matrix = np.zeros((num_nodes, num_absorbent_states))\n",
    "\n",
    "    # Iterate until convergence or maximum iterations reached\n",
    "    for _ in range(max_iter):\n",
    "        prev_probabilities_matrix = probabilities_matrix.copy()\n",
    "        \n",
    "        # Update probabilities for each node\n",
    "        for node in G.nodes():\n",
    "            if node in absorbent_states:\n",
    "                # If the node is an absorbent state, set its probability to 1\n",
    "                absorbent_index = absorbent_states.index(node)\n",
    "                probabilities_matrix[node][absorbent_index] = 1\n",
    "            else:\n",
    "                # Get neighbor probabilities\n",
    "                neighbor_indices = [neighbor for neighbor in G.neighbors(node)]\n",
    "                neighbor_probabilities = prev_probabilities_matrix[neighbor_indices].sum(axis=0)\n",
    "                # If neighbors have probabilities, normalize and update current node's probabilities\n",
    "                total_probability = neighbor_probabilities.sum()\n",
    "                if total_probability > 0:\n",
    "                    probabilities_matrix[node] = neighbor_probabilities / total_probability\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.allclose(prev_probabilities_matrix, probabilities_matrix):\n",
    "            break\n",
    "    \n",
    "    return probabilities_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.        ]\n",
      " [0.         1.        ]\n",
      " [0.72413818 0.27586182]\n",
      " [0.82758685 0.17241315]\n",
      " [0.44827541 0.55172459]\n",
      " [0.62069034 0.37930966]\n",
      " [0.65517123 0.34482877]\n",
      " [0.37930947 0.62069053]\n",
      " [0.5172425  0.4827575 ]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a random graph (you can use any networkx graph)\n",
    "    G = GM\n",
    "\n",
    "    # Apply label propagation algorithm with absorbent states\n",
    "    L = label_propagation_with_absorbent_states(G, absorbent_states)\n",
    "\n",
    "    # Print the probabilities matrix\n",
    "    print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drivetimes: Please note for the toy example the same nodes are indicated for drive-times 5, 10 and 15minutes but for real-world applications like the hospitals more nodes will be included as the drive times extend. The nodes captured in each drive time layer needs to be indicated in the Grids_to_Drivetimes_5min, Grids_to_Drivetimes_10min and Grids_to_Drivetimes_15min txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_name  store_grid\n",
      "0          1           1\n",
      "1          4           1\n",
      "2          6           1\n",
      "3          7           1\n",
      "4          2           2\n",
      "5          5           2\n",
      "6          6           2\n",
      "7          8           2\n"
     ]
    }
   ],
   "source": [
    "# The Grid_Name column indicates the grid that is allocated in the drive time circle of Store_Grid. I.e. grid names 1 and 2 are the only grids with a POI and which have a drivetime circle associated with it.\n",
    "file_path3 = os.path.join(base_path, 'Grids_to_Drivetimes_5min.txt')\n",
    "\n",
    "# Read the file\n",
    "DT5 = pd.read_csv(file_path3, sep='|')\n",
    "print(DT5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_name  store_grid\n",
      "0          1           1\n",
      "1          4           1\n",
      "2          6           1\n",
      "3          7           1\n",
      "4          2           2\n",
      "5          5           2\n",
      "6          6           2\n",
      "7          8           2\n"
     ]
    }
   ],
   "source": [
    "# The Grid_Name column indicates the grid that is allocated in the drive time circle of Store_Grid. I.e. grid names 1 and 2 are the only grids with a POI and which have a drivetime circle associated with it.\n",
    "file_path4 = os.path.join(base_path, 'Grids_to_Drivetimes_10min.txt')\n",
    "\n",
    "# Read the file\n",
    "DT10 = pd.read_csv(file_path4, sep='|')\n",
    "print(DT10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_name  store_grid\n",
      "0          1           1\n",
      "1          4           1\n",
      "2          6           1\n",
      "3          7           1\n",
      "4          2           2\n",
      "5          5           2\n",
      "6          6           2\n",
      "7          8           2\n"
     ]
    }
   ],
   "source": [
    "# The Grid_Name column indicates the grid that is allocated in the drive time circle of Store_Grid. I.e. grid names 1 and 2 are the only grids with a POI and which have a drivetime circle associated with it.\n",
    "file_path5 = os.path.join(base_path, 'Grids_to_Drivetimes_15min.txt')\n",
    "\n",
    "# Read the file\n",
    "DT15 = pd.read_csv(file_path5, sep='|')\n",
    "print(DT15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2\n",
      "1  1  0\n",
      "2  0  1\n",
      "3  0  0\n",
      "4  1  0\n",
      "5  0  1\n",
      "6  1  1\n",
      "7  1  0\n",
      "8  0  1\n",
      "9  0  0\n"
     ]
    }
   ],
   "source": [
    "#5 minute drive time mappings\n",
    "#Create and indicator matrix with the columns the POIs and the rows indicating which nodes are in the drive-times of those POIs\n",
    "n_cols, n_rows = absorbant_States+1, nodes+1\n",
    "Dist5 = np.zeros((n_rows, n_cols), dtype=np.int32)\n",
    "\n",
    "Dist5[0,:] = np.arange(n_cols)\n",
    "Dist5[:,0] = np.arange(n_rows)\n",
    "\n",
    "d_selection5 = pd.DataFrame(DT5, columns = ['grid_name','store_grid'])\n",
    "\n",
    "for i in range(len(d_selection5)):\n",
    "    Dist5[d_selection5.loc[i, \"grid_name\"],d_selection5.loc[i, \"store_grid\"]]=1\n",
    "\n",
    "Dist5=pd.DataFrame(Dist5)\n",
    "Dist5 = Dist5.iloc[1: , 1:]\n",
    "Dist5=pd.DataFrame(Dist5)\n",
    "print(Dist5)\n",
    "\n",
    "myArray5 = np.where(Dist5==0, Dist5, L)\n",
    "myArray5[0:absorbant_States,0:absorbant_States]=identity_abs\n",
    "res5 = myArray5/myArray5.sum(axis=1)[:,None]\n",
    "res5=pd.DataFrame(res5)\n",
    "res5=res5.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2\n",
      "1  1  0\n",
      "2  0  1\n",
      "3  0  0\n",
      "4  1  0\n",
      "5  0  1\n",
      "6  1  1\n",
      "7  1  0\n",
      "8  0  1\n",
      "9  0  0\n"
     ]
    }
   ],
   "source": [
    "#10 minute drive time mappings\n",
    "#Create and indicator matrix with the columns the POIs and the rows indicating which nodes are in the drive-times of those POIs\n",
    "n_cols, n_rows = absorbant_States+1, nodes+1\n",
    "Dist10 = np.zeros((n_rows, n_cols), dtype=np.int32)\n",
    "\n",
    "Dist10[0,:] = np.arange(n_cols)\n",
    "Dist10[:,0] = np.arange(n_rows)\n",
    "\n",
    "d_selection10 = pd.DataFrame(DT10, columns = ['grid_name','store_grid'])\n",
    "\n",
    "for i in range(len(d_selection10)):\n",
    "    Dist10[d_selection10.loc[i, \"grid_name\"],d_selection10.loc[i, \"store_grid\"]]=1\n",
    "\n",
    "Dist10=pd.DataFrame(Dist10)\n",
    "Dist10 = Dist10.iloc[1: , 1:]\n",
    "Dist10=pd.DataFrame(Dist10)\n",
    "print(Dist10)\n",
    "\n",
    "myArray10 = np.where(Dist10==0, Dist10, L)\n",
    "myArray10[0:absorbant_States,0:absorbant_States]=identity_abs\n",
    "res10 = myArray10/myArray10.sum(axis=1)[:,None]\n",
    "res10=pd.DataFrame(res10)\n",
    "res10=res10.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2\n",
      "1  1  0\n",
      "2  0  1\n",
      "3  0  0\n",
      "4  1  0\n",
      "5  0  1\n",
      "6  1  1\n",
      "7  1  0\n",
      "8  0  1\n",
      "9  0  0\n"
     ]
    }
   ],
   "source": [
    "#15 minute drive time mappings\n",
    "#Create and indicator matrix with the columns the POIs and the rows indicating which nodes are in the drive-times of those POIs\n",
    "n_cols, n_rows = absorbant_States+1, nodes+1\n",
    "Dist15 = np.zeros((n_rows, n_cols), dtype=np.int32)\n",
    "\n",
    "Dist15[0,:] = np.arange(n_cols)\n",
    "Dist15[:,0] = np.arange(n_rows)\n",
    "\n",
    "d_selection15 = pd.DataFrame(DT15, columns = ['grid_name','store_grid'])\n",
    "\n",
    "for i in range(len(d_selection15)):\n",
    "    Dist15[d_selection15.loc[i, \"grid_name\"],d_selection15.loc[i, \"store_grid\"]]=1\n",
    "\n",
    "Dist15=pd.DataFrame(Dist15)\n",
    "Dist15 = Dist15.iloc[1: , 1:]\n",
    "Dist15=pd.DataFrame(Dist15)\n",
    "print(Dist15)\n",
    "\n",
    "myArray15 = np.where(Dist15==0, Dist15, L)\n",
    "myArray15[0:absorbant_States,0:absorbant_States]=identity_abs\n",
    "res15 = myArray10/myArray15.sum(axis=1)[:,None]\n",
    "res15=pd.DataFrame(res15)\n",
    "res15=res15.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply and demand to calculate supply-demand ratio and accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_name  Total\n",
      "0          1      1\n",
      "1          2      1\n",
      "2          3      1\n",
      "3          4      1\n",
      "4          5      1\n",
      "5          6      1\n",
      "6          7      1\n",
      "7          8      1\n",
      "8          9      1\n"
     ]
    }
   ],
   "source": [
    "#The Demand for each grid in the toy example is 1\n",
    "file_path6 = os.path.join(base_path, 'Grid_Demand.txt')\n",
    "\n",
    "# Read the file\n",
    "Grid_Demand = pd.read_csv(file_path6, sep='|')\n",
    "\n",
    "# Convert grid_name to numeric if it's stored as string\n",
    "Grid_Demand['grid_name'] = Grid_Demand['grid_name'].astype(int)\n",
    "# Now sort\n",
    "Grid_Demand.sort_values('grid_name', inplace=True)\n",
    "Grid_Demand.reset_index(drop=True, inplace=True)\n",
    "print(Grid_Demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_name  total_sales\n",
      "0          1            4\n",
      "1          2            4\n"
     ]
    }
   ],
   "source": [
    "# The supply for the toy example for P1 and P2 is 4\n",
    "file_path7 = os.path.join(base_path, 'Grid_Supply.txt')\n",
    "\n",
    "# Read the file\n",
    "Grid_Supply = pd.read_csv(file_path7, sep='|')\n",
    "print(Grid_Supply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_name</th>\n",
       "      <th>Total_Grid_5min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_name  Total_Grid_5min\n",
       "0          1             3.62\n",
       "1          2             3.38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the total demand per grid based on the drive time rings: Demand at 5 minute drive-times\n",
    "Grid_Demand=pd.DataFrame(Grid_Demand)\n",
    "Grid_T=Grid_Demand.Total\n",
    "res5_T=res5.T\n",
    "\n",
    "Grid_Demand_5min=np.multiply(res5_T,Grid_T)\n",
    "Grid_Demand_5min=Grid_Demand_5min.T\n",
    "\n",
    "Total_Grid_Demand_5min=round(Grid_Demand_5min.sum(axis='rows'),2)\n",
    "Total_Grid_Demand_5min=pd.DataFrame(Total_Grid_Demand_5min)\n",
    "Total_Grid_Demand_5min.rename(columns={0:'Total_Grid_5min'})\n",
    "Total_Grid_Demand_5min.insert(0, 'grid_name', range(1, 1 + len(Total_Grid_Demand_5min)))\n",
    "Total_Grid_Demand_5min.rename(columns={0:'Total_Grid_5min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_name</th>\n",
       "      <th>Total_Grid_10min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_name  Total_Grid_10min\n",
       "0          1              3.62\n",
       "1          2              3.38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the total demand per grid based on the drive time rings: Demand at 10 minute drive-times\n",
    "Grid_Demand=pd.DataFrame(Grid_Demand)\n",
    "Grid_T=Grid_Demand.Total\n",
    "res10_T=res10.T\n",
    "\n",
    "Grid_Demand_10min=np.multiply(res10_T,Grid_T)\n",
    "Grid_Demand_10min=Grid_Demand_10min.T\n",
    "Total_Grid_Demand_10min=round(Grid_Demand_10min.sum(axis='rows'),2)\n",
    "Total_Grid_Demand_10min=pd.DataFrame(Total_Grid_Demand_10min)\n",
    "Total_Grid_Demand_10min.rename(columns={0:'Total_Grid_10min'})\n",
    "Total_Grid_Demand_10min.insert(0, 'grid_name', range(1, 1 + len(Total_Grid_Demand_10min)))\n",
    "Total_Grid_Demand_10min.rename(columns={0:'Total_Grid_10min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_name</th>\n",
       "      <th>Total_Grid_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_name  Total_Grid_15min\n",
       "0          1              3.62\n",
       "1          2              3.38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the total demand per grid based on the drive time rings: Demand at 15 minute drive-times\n",
    "Grid_Demand=pd.DataFrame(Grid_Demand)\n",
    "Grid_T=Grid_Demand.Total\n",
    "res15_T=res15.T\n",
    "\n",
    "Grid_Demand_15min=np.multiply(res15_T,Grid_T)\n",
    "Grid_Demand_15min=Grid_Demand_15min.T\n",
    "Total_Grid_Demand_15min=round(Grid_Demand_15min.sum(axis='rows'),2)\n",
    "Total_Grid_Demand_15min=pd.DataFrame(Total_Grid_Demand_15min)\n",
    "Total_Grid_Demand_15min.rename(columns={0:'Total_Grid_15min'})\n",
    "Total_Grid_Demand_15min.insert(0, 'grid_name', range(1, 1 + len(Total_Grid_Demand_15min)))\n",
    "Total_Grid_Demand_15min.rename(columns={0:'Total_Grid_15min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GRID_NAME  Total_Sales  Total_Demand_5min  Total_Demand_10min  \\\n",
      "0          1            4               3.62                3.62   \n",
      "1          2            4               3.38                3.38   \n",
      "\n",
      "   Total_Demand_15min  \n",
      "0                3.62  \n",
      "1                3.38  \n"
     ]
    }
   ],
   "source": [
    "# merge all drive times together and supply\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['grid_name'],how='outer'), (Grid_Supply,Total_Grid_Demand_5min,Total_Grid_Demand_10min,Total_Grid_Demand_15min))        \n",
    "df_merged=pd.DataFrame(df_merged)\n",
    "df_merged.set_axis(['GRID_NAME', 'Total_Sales','Total_Demand_5min','Total_Demand_10min','Total_Demand_15min'], axis='columns', inplace=True)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GRID_NAME  Total_Sales  Total_Demand_5min  Total_Demand_10min  \\\n",
      "0          1            4               3.62                3.62   \n",
      "1          2            4               3.38                3.38   \n",
      "\n",
      "   Total_Demand_15min  AR_5min  AR_10min  AR_15min  \n",
      "0                3.62     1.10      1.10      1.10  \n",
      "1                3.38     1.18      1.18      1.18  \n"
     ]
    }
   ],
   "source": [
    "#Add Supply-Demand Ratio for each drive-time. Since for the toy example all drivetimes are the same, the supply-demand ratio is also the same for 5,10 and 15min\n",
    "df_merged['Total_Sales'].fillna(0, inplace=True)\n",
    "df_merged['Total_Demand_5min'].fillna(0, inplace=True)\n",
    "\n",
    "df_merged['Total_Sales'] = pd.to_numeric(df_merged['Total_Sales'], errors='coerce')\n",
    "df_merged['Total_Demand_5min'] = pd.to_numeric(df_merged['Total_Demand_5min'], errors='coerce')\n",
    "\n",
    "df_merged['AR_5min']=df_merged['Total_Sales']/df_merged['Total_Demand_5min']\n",
    "df_merged['AR_10min']=df_merged['Total_Sales']/df_merged['Total_Demand_10min']\n",
    "df_merged['AR_15min']=df_merged['Total_Sales']/df_merged['Total_Demand_15min']\n",
    "\n",
    "df_merged=pd.DataFrame(df_merged)\n",
    "df_merged.fillna(0, inplace=True)\n",
    "df_merged.sort_values(['GRID_NAME'], inplace=True)\n",
    "df_merged = df_merged.round(2)\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the accessibility per grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Accessibility DataFrame:\n",
      "   Accessibility_5min  Accessibility_10min  Accessibility_15min\n",
      "1                1.10                 1.10                 1.10\n",
      "2                1.18                 1.18                 1.18\n",
      "3                0.00                 0.00                 0.00\n",
      "4                1.10                 1.10                 1.10\n",
      "5                1.18                 1.18                 1.18\n",
      "6                2.28                 2.28                 2.28\n",
      "7                1.10                 1.10                 1.10\n",
      "8                1.18                 1.18                 1.18\n",
      "9                0.00                 0.00                 0.00\n"
     ]
    }
   ],
   "source": [
    "Accessibility_5min = np.matmul(Dist5,df_merged.AR_5min)\n",
    "Accessibility_10min = np.matmul(Dist10,df_merged.AR_10min)\n",
    "Accessibility_15min = np.matmul(Dist15,df_merged.AR_15min)\n",
    "\n",
    "Accessibility = [Accessibility_5min,Accessibility_10min,Accessibility_15min]\n",
    "Accessibility=pd.DataFrame(Accessibility)\n",
    "Accessibility=Accessibility.T\n",
    "Accessibility.set_axis(['Accessibility_5min', 'Accessibility_10min', 'Accessibility_15min'], axis='columns', inplace=True)   \n",
    "\n",
    "# Round all values to 2 decimal places\n",
    "Accessibility = Accessibility.round(2)\n",
    "\n",
    "print(\"Updated Accessibility DataFrame:\")\n",
    "print(Accessibility)\n",
    "#The accessibility for grid v5 which in the ordered set V={v2,v7,v1,v3,v4,v5,v6,v8,v9} is grid_name 6 is 2.28\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Profiling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
